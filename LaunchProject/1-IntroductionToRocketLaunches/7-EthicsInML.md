# Embrace Ethics in Data Science and Machine Learning

The last high level concept on machine learning that is important to understand is ethics. Ethics plays a role in every part of the data science lifecyle. From determining what question you want to answer, to the availability of your model, ethics is always something you should be thinking of. 

In the berry example from the previous unit we saw that there was a big piece of missing data from the training and testing datasets: The pressence of thimbleberries. While a particular type of berry might seem trivial, this represents a much larger problem. We've seen in recent studies that huge populations of people are sometimes left initial data collection which can skew results and be life threatning. For example, did you know that the symptoms of heart attacks in men and women are often very different?

## Handling Ethics with Rocket Launches

While we don't have all of knowledge and expertise of the incredible NASA scientists and collaborators that ensure the highest probability of a safe and successful launch, we can try to be as ethical as we can with the limited data that we do have. 

In the remaining modules of this Learning Path, we will explore how weather data we can find on publicly available sites can help us understand what a successful launch day looks like. We have 64 crewed and uncrewed rocket launches in our data set. Which means we can look at the weather on those 64 days to try to get an accurate understanding of what a successful launch day looks like. However, we only have 1 rocket launch that was pushed back (or, "unsuccessful") due to weather. 

Thinking about our berries, this is why the analysis that we will perform is not one that NASA would ever use when real lives were at risk. This analysis is an introduction into the type of analysis that we might begin with, but requires significantly more data and subject matter expertise before it should be used for any kind of real decision making. 

Just like with the berry example, if we don't have a complete representation of data (eg we're missing raspberries or pushed launched dates) then we won't know when to look out for those. This is why data science problems require so much rigor, and require iterations. With each new level of knowledge we gain from our data, we learn what other data might be missing, what new questions to ask, and how we might prioritize the data to yield more accurate understandings of the world around us.